---
title: 模型评估和选择
description: 模型的评估方法，性能度量
---

训练集上产生经验误差，新样本产生泛化误差。

模型在新样本可能发生过拟合和欠拟合，只能缓解不能完全避免。

## 评估方法

可以引入评估方法：

- 留出法：可以采用分层采样，使用约 2/3~4/5 的样本用于训练。

- 交叉验证：分部分划分和分层采样，进行 k 次训练和测试，常用的是 10 折测试。当样本与划分数相同，即留一法，比较准确但成本比较高。

- 自助法：就是放回式随机采样，约有 1/3 样本用于测试，但会引入一定估计偏差

调参过程一般选择范围和步长，用验证集进行评估。

## 性能度量

对于回归任务，使用均方误差

- 错误率和精度：就是分类错误的占比，反映二分任务或多分类任务的效果。

- 查准率与查全率：查准率就正向分类中正确的，查准率是正确中分类出正确的（二者不能兼得，要选择二者的平衡点）

  其中可以用 P-R 图来进行直观显示。二者到平衡点（BEP）即查准率 = 查全率，可以用于比较学习器效果。

  更多使用 F1 度量：
  $$
  F1 = \frac{2\times P \times R }{ P + R} = \frac{2 \times TP}{样例总数 + TP - TN}
  $$

  其一般形式：
  $$
  F_{\beta}=\frac{(1 + \beta^{2}) \times P \times R  }{(\beta^{2} \times P  ) + R}
  $$

- 通过一个截断点来确定正例和反例，重视查准则靠前，重视查全则靠后进行截断

  通过 ROC 曲线可以平衡真正例率和假正例率，而 AUC 可以比较性能，上方面积反映正例，下方反映假正例。

- 代价及其曲线：错误具有非均等价值，可以列写代价矩阵：

  | 类别 | 0      | 1      |
  | ---- | ------ | ------ |
  | 0    | 0      | cost01 |
  | 1    | cost10 | 0      |
